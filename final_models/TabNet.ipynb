{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQIKjJiw2EzB",
        "outputId": "dfd28673-a6b0-45c7-8bee-b7414dbb119f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.47)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.2 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKa9GgoG35Zc",
        "outputId": "60dd5791-23c1-4e75-bb42-519bc8de7c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_tabnet\n",
            "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from pytorch_tabnet) (1.13.1+cu116)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.9/dist-packages (from pytorch_tabnet) (1.2.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.9/dist-packages (from pytorch_tabnet) (4.65.0)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.9/dist-packages (from pytorch_tabnet) (1.10.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from pytorch_tabnet) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<2.0,>=1.2->pytorch_tabnet) (4.5.0)\n",
            "Installing collected packages: pytorch_tabnet\n",
            "Successfully installed pytorch_tabnet-4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg85mHKv1_h_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from math import sqrt\n",
        "import os\n",
        "import missingno as msno\n",
        "import calendar\n",
        "import datetime\n",
        "from math import sqrt\n",
        "from collections import defaultdict\n",
        "\n",
        "#시각화\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "#preprocessing\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error, make_scorer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#MModels\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "#최적화\n",
        "# import optuna\n",
        "# from optuna import Trial\n",
        "# from optuna.samplers import TPESampler\n",
        "\n",
        "# #Xai\n",
        "# from functools import partial \n",
        "# import shap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ixd8xiU2Y0P",
        "outputId": "d8bec037-7b4c-4acc-8b58-4d8d763d3069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "\n",
        "target_col = \"count\"\n",
        "drop_cols = [\"datetime\", \"workingday\", \"holiday\", \"Day\", \"Year\", \"Hour\",target_col] #\"sin_hour\", \"cos_hour\"\n",
        "train_x = train.drop(drop_cols, axis=1)\n"
      ],
      "metadata": {
        "id": "3PXTaGXT8e3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = \"/content/drive/MyDrive/함께하조/기계학습과 딥러닝/data/kaggle_data/test_eda.csv\"\n",
        "train_path = \"/content/drive/MyDrive/함께하조/기계학습과 딥러닝/data/kaggle_data/train_eda.csv\"\n",
        "\n",
        "test = pd.read_csv(test_path)\n",
        "train = pd.read_csv(train_path)\n",
        "\n",
        "test.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "train.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "\n",
        "#cat features\n",
        "cat_col = [\"season\", \"Year\",\"weather\", \"Day of week\",\"Month\",\"Day_info\"] #Hour\n",
        "for col in cat_col:\n",
        "    train[col] = train[col].astype(\"category\")\n",
        "    test[col] = test[col].astype(\"category\")\n",
        "\n",
        "#train, valid split\n",
        "days = list(range(1, 15))\n",
        "train_d = train.loc[train['Day'].isin(days)]\n",
        "test_d = train.loc[~(train['Day'].isin(days))]\n",
        "\n",
        "#target, drop, y\n",
        "target_col = \"count\"\n",
        "drop_cols = [\"datetime\", \"workingday\", \"holiday\", \"Day\", \"Year\", \"Hour\",target_col] #\"sin_hour\", \"cos_hour\"\n",
        "\n",
        "x_train, y_train = train_d.drop(drop_cols, axis=1), train_d[target_col]\n",
        "x_test, y_test = test_d.drop(drop_cols, axis=1), test_d[target_col]\n",
        "\n",
        "x_train.reset_index(drop=True, inplace=True)\n",
        "y_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "x_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ec49k5Ha4PAK",
        "outputId": "b2136492-2ea7-40de-ea3a-84142413dffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  season weather  temp  humidity  windspeed Day of week Month Day_info  \\\n",
              "0      1    Good  9.84        81        0.0    Saturday     1  Weekend   \n",
              "1      1    Good  9.02        80        0.0    Saturday     1  Weekend   \n",
              "2      1    Good  9.02        80        0.0    Saturday     1  Weekend   \n",
              "3      1    Good  9.84        75        0.0    Saturday     1  Weekend   \n",
              "4      1    Good  9.84        75        0.0    Saturday     1  Weekend   \n",
              "\n",
              "   sin_hour  cos_hour  \n",
              "0  0.000000  1.000000  \n",
              "1  0.258819  0.965926  \n",
              "2  0.500000  0.866025  \n",
              "3  0.707107  0.707107  \n",
              "4  0.866025  0.500000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69705ace-b3e3-4b07-9ab4-172126d05880\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>Day of week</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day_info</th>\n",
              "      <th>sin_hour</th>\n",
              "      <th>cos_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>0.965926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69705ace-b3e3-4b07-9ab4-172126d05880')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69705ace-b3e3-4b07-9ab4-172126d05880 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69705ace-b3e3-4b07-9ab4-172126d05880');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 카테고리 컬럼의 Label encoding"
      ],
      "metadata": {
        "id": "bNwOg9tp9OaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiColLabelEncoder:\n",
        "    def __init__(self):\n",
        "        self.encoder_dict = defaultdict(LabelEncoder)\n",
        "    \n",
        "    def fit_transform(self, X: pd.DataFrame, columns: list):\n",
        "        if not isinstance(columns, list):\n",
        "            columns = [columns]\n",
        "        \n",
        "        output = X.copy()\n",
        "        output[columns] = X[columns].apply(lambda x: self.encoder_dict[x.name].fit_transform(x))\n",
        "\n",
        "        return output\n",
        "    \n",
        "    def inverse_transform(self, X: pd.DataFrame, columns: list):\n",
        "        if not isinstance(columns, list):\n",
        "            columns = [columns]\n",
        "        \n",
        "        if not all(key in self.encoder_dict for key in columns):\n",
        "            raise KeyError(f\"at leat one of {columns} is not encoded before\")\n",
        "        output = X.copy()\n",
        "        try:\n",
        "            output[columns] = X[columns].apply(lambda x:\n",
        "                                                self.encoder_dict[x.name].inverse_transform(x))\n",
        "        except ValueError:\n",
        "            print(f\"\"\"Need assignment when do \"fit_transform\" function\"\"\")\n",
        "            raise\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "f3zZHOkx6fGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcle =  MultiColLabelEncoder()\n",
        "cat_cols = [\"season\", \"weather\", \"Day of week\", \"Month\", \"Day_info\"] #\"Hour\"\n",
        "xtrain_t = mcle.fit_transform(x_train, columns=cat_cols)\n",
        "xtest_t = mcle.fit_transform(x_test, columns=cat_cols)\n",
        "xtrain_t.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wwFtBY937yuy",
        "outputId": "f8291713-999a-4240-dcc4-b42ab2ca8315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   season  weather  temp  humidity  windspeed  Day of week  Month  Day_info  \\\n",
              "0       0        0  9.84        81        0.0            2      0         0   \n",
              "1       0        0  9.02        80        0.0            2      0         0   \n",
              "2       0        0  9.02        80        0.0            2      0         0   \n",
              "3       0        0  9.84        75        0.0            2      0         0   \n",
              "4       0        0  9.84        75        0.0            2      0         0   \n",
              "\n",
              "   sin_hour  cos_hour  \n",
              "0  0.000000  1.000000  \n",
              "1  0.258819  0.965926  \n",
              "2  0.500000  0.866025  \n",
              "3  0.707107  0.707107  \n",
              "4  0.866025  0.500000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc937503-4838-4b85-aa71-e99b452971d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>Day of week</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day_info</th>\n",
              "      <th>sin_hour</th>\n",
              "      <th>cos_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.84</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>0.965926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc937503-4838-4b85-aa71-e99b452971d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc937503-4838-4b85-aa71-e99b452971d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc937503-4838-4b85-aa71-e99b452971d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Label encoder 역변환 확인 코드드\n",
        "# org = mcle.inverse_transform(xtrain_t, columns=cat_cols)\n",
        "# org.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XvXvo0z18q6Q",
        "outputId": "89ec9064-9150-4523-c07d-395743907124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   season weather  temp  humidity  windspeed Day of week  Month Day_info  \\\n",
              "0       1    Good  9.84        81        0.0    Saturday      1  Weekend   \n",
              "1       1    Good  9.02        80        0.0    Saturday      1  Weekend   \n",
              "2       1    Good  9.02        80        0.0    Saturday      1  Weekend   \n",
              "3       1    Good  9.84        75        0.0    Saturday      1  Weekend   \n",
              "4       1    Good  9.84        75        0.0    Saturday      1  Weekend   \n",
              "\n",
              "   sin_hour  cos_hour  \n",
              "0  0.000000  1.000000  \n",
              "1  0.258819  0.965926  \n",
              "2  0.500000  0.866025  \n",
              "3  0.707107  0.707107  \n",
              "4  0.866025  0.500000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8bb0189-5ce0-44c9-8828-dc682e250605\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>Day of week</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day_info</th>\n",
              "      <th>sin_hour</th>\n",
              "      <th>cos_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>0.965926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8bb0189-5ce0-44c9-8828-dc682e250605')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8bb0189-5ce0-44c9-8828-dc682e250605 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8bb0189-5ce0-44c9-8828-dc682e250605');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_dims = [len(xtrain_t[col].unique()) for col in cat_cols]\n",
        "categorical_dims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iREmKDN-L6l",
        "outputId": "143c3503-9fa7-47fc-9b3a-5ce74086b4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 3, 7, 12, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파라미터 세팅"
      ],
      "metadata": {
        "id": "BzSh4EVq7tBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(xtrain_t.columns)\n",
        "cat_dims = [len(xtrain_t[col].unique()) for col in cat_cols]\n",
        "cat_idxs = [ i for i, f in enumerate(features) if f in cat_cols]\n",
        "\n",
        "print(features)\n",
        "print(cat_idxs)\n",
        "print(cat_dims)"
      ],
      "metadata": {
        "id": "kvveG3409S-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(xtrain_t.columns)\n",
        "cat_dims = [len(xtrain_t[col].unique()) for col in cat_cols]\n",
        "cat_idxs = [ i for i, f in enumerate(features) if f in cat_cols]\n",
        "\n",
        "# define your embedding sizes : here just a random choice(optuna로 설정 뭔지 알아보기)\n",
        "cat_emb_dim = [5, 4, 3, 6, 2, 2, 1, 10]\n",
        "\n",
        "print(features)\n",
        "print(cat_idxs)\n",
        "print(cat_dims)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2OQdY4M9iOw",
        "outputId": "93bba44e-a6e3-4907-da3e-3ad7dcb47ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['season', 'weather', 'temp', 'humidity', 'windspeed', 'Day of week', 'Month', 'Day_info', 'sin_hour', 'cos_hour']\n",
            "[0, 1, 5, 6, 7]\n",
            "[4, 3, 7, 12, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain_t.shape)\n",
        "print(xtest_t.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHraL0kxCsd4",
        "outputId": "e7039493-0d95-4cf1-de67-c551a8c4e818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8026, 10)\n",
            "(2860, 10)\n",
            "(8026,)\n",
            "(2860,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clf = TabNetRegressor(cat_idxs=cat_idxs,\n",
        "#                        cat_dims=cat_dims,\n",
        "#                        cat_emb_dim=5,\n",
        "#                        optimizer_fn=torch.optim.Adam,\n",
        "#                        optimizer_params=dict(lr=1e-2),\n",
        "#                        scheduler_params={\"step_size\":50,\n",
        "#                                          \"gamma\":0.9},\n",
        "#                        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "#                        mask_type='sparsemax' # \"sparsemax\", entmax\n",
        "#                       )"
      ],
      "metadata": {
        "id": "AphKAZrkHTbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(\"Using {}\".format(DEVICE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2w5E2T8Q4EO",
        "outputId": "1cf3585c-3327-4b9c-9d89-89a9eeb3260c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 아래 코드가 완성 코드"
      ],
      "metadata": {
        "id": "foXJ4uIKVWp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.metrics import Metric\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class RMSLE(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = \"rmsle_custom\"\n",
        "        self._maximize = False\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        y_true = np.expm1(y_true)\n",
        "        y_pred = np.expm1(y_pred)\n",
        "\n",
        "        log_true = np.nan_to_num(np.log(y_true+1))\n",
        "        log_pred = np.nan_to_num(np.log(y_pred+1))\n",
        "\n",
        "        output = np.sqrt(np.mean((log_true - log_pred)**2))\n",
        "        return output\n",
        "\n",
        "clf =  TabNetRegressor(cat_idxs=cat_idxs,\n",
        "                       cat_dims=cat_dims,\n",
        "                       cat_emb_dim=5)\n",
        "clf.fit(\n",
        "  xtrain_t.values, np.log1p(np.array(y_train).reshape(-1, 1)),\n",
        "  eval_set=[(xtrain_t.values, np.log1p(np.array(y_train).reshape(-1, 1))),\n",
        "            (xtest_t.values, np.log1p(np.array(y_test).reshape(-1, 1)))],\n",
        "            eval_name=['train', 'valid'],\n",
        "  eval_metric=[\"rmsle\", RMSLE],\n",
        "  max_epochs=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrWykSZaBIpq",
        "outputId": "7ab58498-1eea-48bb-8128-e99770c2cf3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 16.03028| train_rmsle: 0.40713 | train_rmsle_custom: 2.6764  | valid_rmsle: 0.42163 | valid_rmsle_custom: 2.66966 |  0:00:00s\n",
            "epoch 1  | loss: 4.35383 | train_rmsle: 0.23606 | train_rmsle_custom: 3.36565 | valid_rmsle: 0.23124 | valid_rmsle_custom: 3.40532 |  0:00:01s\n",
            "epoch 2  | loss: 2.07594 | train_rmsle: 0.14539 | train_rmsle_custom: 2.49883 | valid_rmsle: 0.13749 | valid_rmsle_custom: 2.50963 |  0:00:02s\n",
            "epoch 3  | loss: 1.47674 | train_rmsle: 0.13011 | train_rmsle_custom: 2.48582 | valid_rmsle: 0.11465 | valid_rmsle_custom: 2.28222 |  0:00:02s\n",
            "epoch 4  | loss: 1.13025 | train_rmsle: 0.12626 | train_rmsle_custom: 2.18417 | valid_rmsle: 0.11299 | valid_rmsle_custom: 2.06984 |  0:00:03s\n",
            "epoch 5  | loss: 0.94119 | train_rmsle: 0.1219  | train_rmsle_custom: 1.92414 | valid_rmsle: 0.10198 | valid_rmsle_custom: 1.78172 |  0:00:03s\n",
            "epoch 6  | loss: 0.79056 | train_rmsle: 0.1144  | train_rmsle_custom: 1.74987 | valid_rmsle: 0.10063 | valid_rmsle_custom: 1.67318 |  0:00:04s\n",
            "epoch 7  | loss: 0.65025 | train_rmsle: 0.10023 | train_rmsle_custom: 1.57856 | valid_rmsle: 0.08688 | valid_rmsle_custom: 1.51639 |  0:00:05s\n",
            "epoch 8  | loss: 0.54955 | train_rmsle: 0.08329 | train_rmsle_custom: 1.33679 | valid_rmsle: 0.07289 | valid_rmsle_custom: 1.28855 |  0:00:06s\n",
            "epoch 9  | loss: 0.50763 | train_rmsle: 0.07182 | train_rmsle_custom: 1.25162 | valid_rmsle: 0.06495 | valid_rmsle_custom: 1.22685 |  0:00:06s\n",
            "epoch 10 | loss: 0.45576 | train_rmsle: 0.04978 | train_rmsle_custom: 1.07276 | valid_rmsle: 0.04606 | valid_rmsle_custom: 1.06097 |  0:00:07s\n",
            "epoch 11 | loss: 0.43624 | train_rmsle: 0.03762 | train_rmsle_custom: 0.93746 | valid_rmsle: 0.03597 | valid_rmsle_custom: 0.93657 |  0:00:08s\n",
            "epoch 12 | loss: 0.40654 | train_rmsle: 0.03555 | train_rmsle_custom: 0.86147 | valid_rmsle: 0.03345 | valid_rmsle_custom: 0.85193 |  0:00:08s\n",
            "epoch 13 | loss: 0.40416 | train_rmsle: 0.03123 | train_rmsle_custom: 0.7876  | valid_rmsle: 0.029   | valid_rmsle_custom: 0.77267 |  0:00:09s\n",
            "epoch 14 | loss: 0.37669 | train_rmsle: 0.03296 | train_rmsle_custom: 0.79424 | valid_rmsle: 0.02929 | valid_rmsle_custom: 0.77231 |  0:00:10s\n",
            "epoch 15 | loss: 0.36467 | train_rmsle: 0.03243 | train_rmsle_custom: 0.81127 | valid_rmsle: 0.03024 | valid_rmsle_custom: 0.79175 |  0:00:10s\n",
            "epoch 16 | loss: 0.36077 | train_rmsle: 0.02774 | train_rmsle_custom: 0.73042 | valid_rmsle: 0.02535 | valid_rmsle_custom: 0.71274 |  0:00:11s\n",
            "epoch 17 | loss: 0.34813 | train_rmsle: 0.02324 | train_rmsle_custom: 0.66394 | valid_rmsle: 0.0224  | valid_rmsle_custom: 0.65284 |  0:00:11s\n",
            "epoch 18 | loss: 0.33748 | train_rmsle: 0.02224 | train_rmsle_custom: 0.64568 | valid_rmsle: 0.02108 | valid_rmsle_custom: 0.63413 |  0:00:12s\n",
            "epoch 19 | loss: 0.33102 | train_rmsle: 0.02015 | train_rmsle_custom: 0.62773 | valid_rmsle: 0.01935 | valid_rmsle_custom: 0.62164 |  0:00:13s\n",
            "epoch 20 | loss: 0.31799 | train_rmsle: 0.02035 | train_rmsle_custom: 0.61386 | valid_rmsle: 0.01848 | valid_rmsle_custom: 0.59895 |  0:00:13s\n",
            "epoch 21 | loss: 0.30685 | train_rmsle: 0.01819 | train_rmsle_custom: 0.58356 | valid_rmsle: 0.01753 | valid_rmsle_custom: 0.57579 |  0:00:14s\n",
            "epoch 22 | loss: 0.31374 | train_rmsle: 0.01899 | train_rmsle_custom: 0.59406 | valid_rmsle: 0.01786 | valid_rmsle_custom: 0.5881  |  0:00:14s\n",
            "epoch 23 | loss: 0.29328 | train_rmsle: 0.01742 | train_rmsle_custom: 0.56998 | valid_rmsle: 0.017   | valid_rmsle_custom: 0.56321 |  0:00:15s\n",
            "epoch 24 | loss: 0.3005  | train_rmsle: 0.0184  | train_rmsle_custom: 0.57436 | valid_rmsle: 0.01715 | valid_rmsle_custom: 0.56066 |  0:00:16s\n",
            "epoch 25 | loss: 0.29472 | train_rmsle: 0.01686 | train_rmsle_custom: 0.55971 | valid_rmsle: 0.01576 | valid_rmsle_custom: 0.5504  |  0:00:16s\n",
            "epoch 26 | loss: 0.28909 | train_rmsle: 0.01592 | train_rmsle_custom: 0.5434  | valid_rmsle: 0.01598 | valid_rmsle_custom: 0.54706 |  0:00:17s\n",
            "epoch 27 | loss: 0.2992  | train_rmsle: 0.01603 | train_rmsle_custom: 0.53762 | valid_rmsle: 0.0162  | valid_rmsle_custom: 0.53825 |  0:00:18s\n",
            "epoch 28 | loss: 0.29287 | train_rmsle: 0.0161  | train_rmsle_custom: 0.56085 | valid_rmsle: 0.01633 | valid_rmsle_custom: 0.57199 |  0:00:19s\n",
            "epoch 29 | loss: 0.27892 | train_rmsle: 0.0141  | train_rmsle_custom: 0.51086 | valid_rmsle: 0.01375 | valid_rmsle_custom: 0.52043 |  0:00:19s\n",
            "epoch 30 | loss: 0.27992 | train_rmsle: 0.01414 | train_rmsle_custom: 0.50998 | valid_rmsle: 0.01395 | valid_rmsle_custom: 0.51822 |  0:00:20s\n",
            "epoch 31 | loss: 0.2806  | train_rmsle: 0.0134  | train_rmsle_custom: 0.49783 | valid_rmsle: 0.01342 | valid_rmsle_custom: 0.5069  |  0:00:21s\n",
            "epoch 32 | loss: 0.27166 | train_rmsle: 0.01295 | train_rmsle_custom: 0.48756 | valid_rmsle: 0.01292 | valid_rmsle_custom: 0.49497 |  0:00:21s\n",
            "epoch 33 | loss: 0.25594 | train_rmsle: 0.01429 | train_rmsle_custom: 0.50718 | valid_rmsle: 0.0136  | valid_rmsle_custom: 0.50201 |  0:00:22s\n",
            "epoch 34 | loss: 0.27204 | train_rmsle: 0.01282 | train_rmsle_custom: 0.48548 | valid_rmsle: 0.01264 | valid_rmsle_custom: 0.48747 |  0:00:22s\n",
            "epoch 35 | loss: 0.25651 | train_rmsle: 0.01239 | train_rmsle_custom: 0.47135 | valid_rmsle: 0.0121  | valid_rmsle_custom: 0.47718 |  0:00:23s\n",
            "epoch 36 | loss: 0.26369 | train_rmsle: 0.01288 | train_rmsle_custom: 0.49611 | valid_rmsle: 0.01281 | valid_rmsle_custom: 0.5065  |  0:00:24s\n",
            "epoch 37 | loss: 0.25518 | train_rmsle: 0.01205 | train_rmsle_custom: 0.46904 | valid_rmsle: 0.01178 | valid_rmsle_custom: 0.47373 |  0:00:24s\n",
            "epoch 38 | loss: 0.24893 | train_rmsle: 0.01209 | train_rmsle_custom: 0.46842 | valid_rmsle: 0.01166 | valid_rmsle_custom: 0.47377 |  0:00:25s\n",
            "epoch 39 | loss: 0.25453 | train_rmsle: 0.01195 | train_rmsle_custom: 0.46836 | valid_rmsle: 0.01191 | valid_rmsle_custom: 0.48128 |  0:00:25s\n",
            "epoch 40 | loss: 0.24099 | train_rmsle: 0.01128 | train_rmsle_custom: 0.45274 | valid_rmsle: 0.01112 | valid_rmsle_custom: 0.46848 |  0:00:26s\n",
            "epoch 41 | loss: 0.24127 | train_rmsle: 0.01101 | train_rmsle_custom: 0.44762 | valid_rmsle: 0.0114  | valid_rmsle_custom: 0.47155 |  0:00:27s\n",
            "epoch 42 | loss: 0.23367 | train_rmsle: 0.01107 | train_rmsle_custom: 0.45287 | valid_rmsle: 0.01157 | valid_rmsle_custom: 0.47121 |  0:00:27s\n",
            "epoch 43 | loss: 0.22673 | train_rmsle: 0.01144 | train_rmsle_custom: 0.44753 | valid_rmsle: 0.01217 | valid_rmsle_custom: 0.47589 |  0:00:28s\n",
            "epoch 44 | loss: 0.22351 | train_rmsle: 0.01078 | train_rmsle_custom: 0.43069 | valid_rmsle: 0.01122 | valid_rmsle_custom: 0.45699 |  0:00:28s\n",
            "epoch 45 | loss: 0.22181 | train_rmsle: 0.01053 | train_rmsle_custom: 0.44438 | valid_rmsle: 0.01103 | valid_rmsle_custom: 0.46845 |  0:00:29s\n",
            "epoch 46 | loss: 0.21963 | train_rmsle: 0.01068 | train_rmsle_custom: 0.43802 | valid_rmsle: 0.0115  | valid_rmsle_custom: 0.47179 |  0:00:30s\n",
            "epoch 47 | loss: 0.20907 | train_rmsle: 0.01022 | train_rmsle_custom: 0.43118 | valid_rmsle: 0.01098 | valid_rmsle_custom: 0.46525 |  0:00:31s\n",
            "epoch 48 | loss: 0.20947 | train_rmsle: 0.01041 | train_rmsle_custom: 0.43385 | valid_rmsle: 0.01106 | valid_rmsle_custom: 0.46907 |  0:00:31s\n",
            "epoch 49 | loss: 0.21185 | train_rmsle: 0.01099 | train_rmsle_custom: 0.44098 | valid_rmsle: 0.01204 | valid_rmsle_custom: 0.48067 |  0:00:32s\n",
            "epoch 50 | loss: 0.20811 | train_rmsle: 0.01021 | train_rmsle_custom: 0.42213 | valid_rmsle: 0.01099 | valid_rmsle_custom: 0.4632  |  0:00:33s\n",
            "epoch 51 | loss: 0.20085 | train_rmsle: 0.01    | train_rmsle_custom: 0.42288 | valid_rmsle: 0.01141 | valid_rmsle_custom: 0.47969 |  0:00:33s\n",
            "epoch 52 | loss: 0.20706 | train_rmsle: 0.00955 | train_rmsle_custom: 0.41048 | valid_rmsle: 0.01115 | valid_rmsle_custom: 0.46563 |  0:00:34s\n",
            "epoch 53 | loss: 0.20843 | train_rmsle: 0.01048 | train_rmsle_custom: 0.43113 | valid_rmsle: 0.01156 | valid_rmsle_custom: 0.47606 |  0:00:34s\n",
            "epoch 54 | loss: 0.20981 | train_rmsle: 0.00936 | train_rmsle_custom: 0.40275 | valid_rmsle: 0.0105  | valid_rmsle_custom: 0.45201 |  0:00:35s\n",
            "epoch 55 | loss: 0.19459 | train_rmsle: 0.00903 | train_rmsle_custom: 0.40012 | valid_rmsle: 0.01043 | valid_rmsle_custom: 0.44962 |  0:00:36s\n",
            "epoch 56 | loss: 0.19494 | train_rmsle: 0.00893 | train_rmsle_custom: 0.39534 | valid_rmsle: 0.01035 | valid_rmsle_custom: 0.44647 |  0:00:36s\n",
            "epoch 57 | loss: 0.19362 | train_rmsle: 0.00872 | train_rmsle_custom: 0.3932  | valid_rmsle: 0.01021 | valid_rmsle_custom: 0.44415 |  0:00:37s\n",
            "epoch 58 | loss: 0.18661 | train_rmsle: 0.00883 | train_rmsle_custom: 0.39667 | valid_rmsle: 0.01043 | valid_rmsle_custom: 0.45152 |  0:00:37s\n",
            "epoch 59 | loss: 0.19448 | train_rmsle: 0.00908 | train_rmsle_custom: 0.39652 | valid_rmsle: 0.0105  | valid_rmsle_custom: 0.44675 |  0:00:38s\n",
            "epoch 60 | loss: 0.1853  | train_rmsle: 0.00882 | train_rmsle_custom: 0.40233 | valid_rmsle: 0.01084 | valid_rmsle_custom: 0.46271 |  0:00:39s\n",
            "epoch 61 | loss: 0.18583 | train_rmsle: 0.00888 | train_rmsle_custom: 0.40312 | valid_rmsle: 0.01072 | valid_rmsle_custom: 0.45824 |  0:00:39s\n",
            "epoch 62 | loss: 0.1856  | train_rmsle: 0.00889 | train_rmsle_custom: 0.39603 | valid_rmsle: 0.01054 | valid_rmsle_custom: 0.44817 |  0:00:40s\n",
            "epoch 63 | loss: 0.1894  | train_rmsle: 0.00912 | train_rmsle_custom: 0.41142 | valid_rmsle: 0.01067 | valid_rmsle_custom: 0.46239 |  0:00:40s\n",
            "epoch 64 | loss: 0.20121 | train_rmsle: 0.00909 | train_rmsle_custom: 0.39891 | valid_rmsle: 0.01037 | valid_rmsle_custom: 0.44834 |  0:00:41s\n",
            "epoch 65 | loss: 0.18912 | train_rmsle: 0.00881 | train_rmsle_custom: 0.39292 | valid_rmsle: 0.01054 | valid_rmsle_custom: 0.44753 |  0:00:42s\n",
            "epoch 66 | loss: 0.1828  | train_rmsle: 0.00856 | train_rmsle_custom: 0.3855  | valid_rmsle: 0.0098  | valid_rmsle_custom: 0.43208 |  0:00:42s\n",
            "epoch 67 | loss: 0.18785 | train_rmsle: 0.0086  | train_rmsle_custom: 0.39385 | valid_rmsle: 0.01049 | valid_rmsle_custom: 0.45108 |  0:00:43s\n",
            "epoch 68 | loss: 0.18778 | train_rmsle: 0.00869 | train_rmsle_custom: 0.40056 | valid_rmsle: 0.0104  | valid_rmsle_custom: 0.45193 |  0:00:44s\n",
            "epoch 69 | loss: 0.18425 | train_rmsle: 0.00836 | train_rmsle_custom: 0.38506 | valid_rmsle: 0.0104  | valid_rmsle_custom: 0.44287 |  0:00:45s\n",
            "epoch 70 | loss: 0.17631 | train_rmsle: 0.00854 | train_rmsle_custom: 0.39022 | valid_rmsle: 0.01058 | valid_rmsle_custom: 0.44715 |  0:00:45s\n",
            "epoch 71 | loss: 0.18658 | train_rmsle: 0.00835 | train_rmsle_custom: 0.38024 | valid_rmsle: 0.01004 | valid_rmsle_custom: 0.43405 |  0:00:46s\n",
            "epoch 72 | loss: 0.17855 | train_rmsle: 0.00934 | train_rmsle_custom: 0.39383 | valid_rmsle: 0.0105  | valid_rmsle_custom: 0.44583 |  0:00:47s\n",
            "epoch 73 | loss: 0.18422 | train_rmsle: 0.00885 | train_rmsle_custom: 0.39256 | valid_rmsle: 0.01107 | valid_rmsle_custom: 0.4518  |  0:00:47s\n",
            "epoch 74 | loss: 0.18042 | train_rmsle: 0.00878 | train_rmsle_custom: 0.39038 | valid_rmsle: 0.01052 | valid_rmsle_custom: 0.44936 |  0:00:48s\n",
            "epoch 75 | loss: 0.18706 | train_rmsle: 0.00847 | train_rmsle_custom: 0.37864 | valid_rmsle: 0.01008 | valid_rmsle_custom: 0.43532 |  0:00:48s\n",
            "epoch 76 | loss: 0.17536 | train_rmsle: 0.00825 | train_rmsle_custom: 0.37643 | valid_rmsle: 0.00984 | valid_rmsle_custom: 0.4323  |  0:00:49s\n",
            "\n",
            "Early stopping occurred at epoch 76 with best_epoch = 66 and best_valid_rmsle_custom = 0.43208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_rmsle = clf.history[\"train_rmsle_custom\"]\n",
        "valid_rmsle = clf.history[\"valid_rmsle_custom\"]"
      ],
      "metadata": {
        "id": "0IOQxf1US4lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=list(range(len(train_rmsle))), y= train_rmsle, name=\"train\"))\n",
        "fig.add_trace(go.Scatter(x=list(range(len(train_rmsle))), y= valid_rmsle, name=\"valid\"))\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "PbiIus1eT7Tf",
        "outputId": "8c8ec865-e29a-40a1-90ad-3a5a2d6a522b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"81646963-84a1-4990-9e04-4d26b7bb56d4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"81646963-84a1-4990-9e04-4d26b7bb56d4\")) {                    Plotly.newPlot(                        \"81646963-84a1-4990-9e04-4d26b7bb56d4\",                        [{\"name\":\"train\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76],\"y\":[2.6764018673488943,3.3656521578431264,2.498828302381679,2.4858234601164195,2.184170536825462,1.9241382941556509,1.7498657021354156,1.5785618546171774,1.3367925198811186,1.2516183486446586,1.0727602595322068,0.9374578139175753,0.8614746328624409,0.7876003876547173,0.7942362905299516,0.8112664369462111,0.7304221264898014,0.6639414812220992,0.6456752773098966,0.6277310963754472,0.6138623042898844,0.5835636423060601,0.5940640218169132,0.5699770704461322,0.5743632043229857,0.5597075613159637,0.5433977662984822,0.5376247446894946,0.5608474854630846,0.5108580821013934,0.5099787118192713,0.4978334843530698,0.48756026449656625,0.507183142128867,0.48548419815390254,0.471346491115497,0.4961100525103633,0.46903558932434897,0.4684227054562489,0.46835744399846035,0.4527353846513328,0.4476181831512483,0.45286552814483216,0.4475270425320665,0.43068918830651814,0.4443779338581737,0.4380247947208702,0.43118322504416534,0.4338496494575413,0.44097671579807646,0.42213168402141404,0.4228751436100328,0.4104770185862538,0.4311307069153312,0.40275324546800984,0.40011942172708254,0.3953368586035741,0.3931995209848358,0.3966671003328806,0.39651504251623826,0.402330460772717,0.40312294133091614,0.39603134262734874,0.411416587359439,0.3989079700415086,0.3929209649862569,0.3855026916582515,0.3938459813927222,0.4005596555464605,0.3850582141441951,0.3902202369269986,0.38023820039603007,0.39383453579826877,0.3925612052913745,0.3903776741344701,0.3786365028061992,0.37642898977784955],\"type\":\"scatter\"},{\"name\":\"valid\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76],\"y\":[2.6696586407013103,3.4053154715382132,2.509631031094385,2.282215290943247,2.06983877939027,1.7817243692949367,1.6731769957554277,1.5163944998876122,1.2885520632300516,1.2268509404855812,1.0609702680571316,0.9365711178704126,0.8519345290809516,0.7726676190649198,0.7723111733595645,0.7917539941627367,0.7127415035177548,0.6528359800754814,0.6341313869808921,0.6216377407392724,0.5989452995005261,0.5757911877602471,0.5880970238858567,0.5632089249188932,0.5606623352140301,0.5504020831636727,0.5470628975183205,0.5382545112944899,0.5719922877871787,0.5204292006447931,0.5182216997481741,0.5068966601560684,0.49496533035037066,0.5020079471745649,0.48746743404472653,0.47717948369042446,0.5065041559345808,0.4737336141478662,0.4737654862362105,0.4812778480411683,0.4684804004986979,0.47154751612443757,0.47121496726150425,0.47588865377850814,0.4569947531813471,0.46845084031088213,0.47178748732957276,0.4652494576035317,0.4690696963298081,0.48066909883543335,0.4632008661502247,0.47968849457295437,0.4656312357608413,0.4760604165127898,0.4520081597027545,0.4496163651533136,0.4464704642358323,0.4441520404944473,0.4515205355813664,0.4467542367101011,0.4627119891121627,0.45824020334799836,0.44816567446496214,0.46239129917641253,0.44833568925481415,0.447534896657569,0.43208331875120776,0.4510823309490802,0.4519308778221581,0.4428707220044883,0.4471518340080326,0.43405057468672564,0.4458287639354992,0.4517984855536958,0.4493637941928993,0.43532393351441034,0.4322959076203551],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('81646963-84a1-4990-9e04-4d26b7bb56d4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tt = clf.predict(xtest_t.values)\n",
        "np.expm1(tt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxXq6g6SRVig",
        "outputId": "27d57ad8-e0e4-4e80-b809-23a84dd083fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 51.57367 ],\n",
              "       [ 24.112095],\n",
              "       [ 15.035192],\n",
              "       ...,\n",
              "       [140.89789 ],\n",
              "       [107.95928 ],\n",
              "       [ 46.677063]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isBE51r1Rk6A",
        "outputId": "f1b09bcc-0f58-4281-ff35-118ceea263cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324       28\n",
              "325       20\n",
              "326       12\n",
              "327        8\n",
              "328        5\n",
              "        ... \n",
              "10881    336\n",
              "10882    241\n",
              "10883    168\n",
              "10884    129\n",
              "10885     88\n",
              "Name: count, Length: 2860, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(mean_squared_log_error(y_test, np.expm1(tt)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkN-Z5CrRyYP",
        "outputId": "f91b73fa-bced-4e6d-9c63-b6336ea9bd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.520429200734873"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Objective(trial):\n",
        "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
        "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
        "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
        "    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n",
        "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
        "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
        "    cat_emb_dim = trial.suggest_int(\"cat_emb_dim\", 1, 10)\n",
        "    tabnet_params = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n",
        "                     lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n",
        "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
        "                     mask_type=mask_type, n_shared=n_shared,\n",
        "                     scheduler_params=dict(mode=\"min\",\n",
        "                                           patience=trial.suggest_int(\"patienceScheduler\",low=3,high=10),\n",
        "                                           min_lr=1e-5,\n",
        "                                           factor=0.5,),\n",
        "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "                     verbose=0,\n",
        "                     cat_idxs = cat_idxs,\n",
        "                     cat_dims = cat_dims,\n",
        "                     cat_emb_dim=cat_emb_dim\n",
        "                     )\n",
        "    n_splits=5\n",
        "    random_state=42\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    scores = []\n",
        "\n",
        "    #local_train, local_valid를 5번 만들어서 수행\n",
        "    for train_index, valid_index in kf.split(X=xtrain_t, y=y_train):\n",
        "        X_train, Y_train = xtrain_t.iloc[train_index].values, np.array(y_train[train_index]).reshape(-1, 1)\n",
        "        X_valid, Y_valid = xtrain_t.iloc[valid_index].values, np.array(y_train[valid_index]).reshape(-1, 1)\n",
        "\n",
        "        regressor = TabNetRegressor(**tabnet_params)\n",
        "        regressor.fit(X_train=X_train, y_train=Y_train,\n",
        "                  eval_set=[(X_valid, Y_valid)],\n",
        "                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
        "                  eval_metric=[\"rmsle\"])\n",
        "        \n",
        "        scores.append(regressor.best_cost)\n",
        "\n",
        "    avg = np.mean(scores)\n",
        "    return avg\n",
        "    \n",
        "sampler = TPESampler(seed=42)\n",
        "study = optuna.create_study(\n",
        "    study_name=\"TabNet\",\n",
        "    direction=\"minimize\",\n",
        "    sampler=sampler,\n",
        ")\n",
        "study.optimize(Objective, n_trials=20)\n",
        "print(\"Best Score:\", study.best_value)\n",
        "print(\"Best trial:\", study.best_trial.params)"
      ],
      "metadata": {
        "id": "jGZlP_t--0UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.metrics import Metric\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class RMSLE(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = \"rmsle_custom\"\n",
        "        self._maximize = False\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        y_true = np.expm1(y_true)\n",
        "        y_pred = np.expm1(y_pred)\n",
        "\n",
        "        log_true = np.nan_to_num(np.log(y_true+1))\n",
        "        log_pred = np.nan_to_num(np.log(y_pred+1))\n",
        "\n",
        "        output = np.sqrt(np.mean((log_true - log_pred)**2))\n",
        "        return output\n",
        "\n",
        "def Objective(trial):\n",
        "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
        "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
        "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
        "    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n",
        "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
        "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
        "    cat_emb_dim = trial.suggest_int(\"cat_emb_dim\", 1, 10)\n",
        "    tabnet_params = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n",
        "                     lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n",
        "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
        "                     mask_type=mask_type, n_shared=n_shared,\n",
        "                     scheduler_params=dict(mode=\"min\",\n",
        "                                           patience=trial.suggest_int(\"patienceScheduler\",low=3,high=10),\n",
        "                                           min_lr=1e-5,\n",
        "                                           factor=0.5,),\n",
        "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "                     verbose=0,\n",
        "                     cat_idxs = cat_idxs,\n",
        "                     cat_dims = cat_dims,\n",
        "                     cat_emb_dim=cat_emb_dim\n",
        "                     )\n",
        "    n_splits=5\n",
        "    random_state=42\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    scores = []\n",
        "\n",
        "    #local_train, local_valid를 5번 만들어서 수행\n",
        "    for train_index, valid_index in kf.split(X=xtrain_t, y=y_train):\n",
        "        X_train, Y_train = xtrain_t.iloc[train_index].values, np.array(y_train[train_index]).reshape(-1, 1)\n",
        "        X_valid, Y_valid = xtrain_t.iloc[valid_index].values, np.array(y_train[valid_index]).reshape(-1, 1)\n",
        "\n",
        "        regressor = TabNetRegressor(**tabnet_params)\n",
        "        regressor.fit(X_train=X_train, y_train=Y_train,\n",
        "                  eval_set=[(X_valid, Y_valid)],\n",
        "                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
        "                  eval_metric=[\"rmsle\"])\n",
        "        \n",
        "        scores.append(regressor.best_cost)\n",
        "\n",
        "    avg = np.mean(scores)\n",
        "    return avg\n",
        "    \n",
        "sampler = TPESampler(seed=42)\n",
        "study = optuna.create_study(\n",
        "    study_name=\"TabNet\",\n",
        "    direction=\"minimize\",\n",
        "    sampler=sampler,\n",
        ")\n",
        "study.optimize(Objective, n_trials=20)\n",
        "print(\"Best Score:\", study.best_value)\n",
        "print(\"Best trial:\", study.best_trial.params)"
      ],
      "metadata": {
        "id": "u2IcqQtlIMs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = TPESampler(seed=42)\n",
        "study = optuna.create_study(\n",
        "    study_name=\"TabNet\",\n",
        "    direction=\"minimize\",\n",
        "    sampler=sampler,\n",
        ")\n",
        "study.optimize(Objective, n_trials=20)\n",
        "print(\"Best Score:\", study.best_value)\n",
        "print(\"Best trial:\", study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnIn2mTYMWsf",
        "outputId": "850d16d7-35f2-4bad-b684-a43fd6247621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-03-23 18:04:45,111]\u001b[0m A new study created in memory with name: TabNet\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_rmsle = 3.49592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_rmsle = 2.47297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_rmsle = 2.18117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_rmsle = 3.53058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_rmsle = 3.87327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:04:59,001]\u001b[0m Trial 0 finished with value: 3.110781105755272 and parameters: {'mask_type': 'sparsemax', 'n_da': 64, 'n_steps': 2, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 1.493656855461763e-06, 'cat_emb_dim': 9, 'patienceScheduler': 7, 'patience': 26, 'epochs': 3}. Best is trial 0 with value: 3.110781105755272.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 14 with best_epoch = 13 and best_val_0_rmsle = 0.69662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 14 with best_epoch = 12 and best_val_0_rmsle = 0.89568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 14 with best_epoch = 13 and best_val_0_rmsle = 0.48479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 14 with best_epoch = 13 and best_val_0_rmsle = 0.77193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 14 with best_epoch = 13 and best_val_0_rmsle = 0.57096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:05:33,640]\u001b[0m Trial 1 finished with value: 0.6839957645722059 and parameters: {'mask_type': 'entmax', 'n_da': 56, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 1, 'lambda_sparse': 3.752055855124284e-05, 'cat_emb_dim': 5, 'patienceScheduler': 5, 'patience': 24, 'epochs': 14}. Best is trial 1 with value: 0.6839957645722059.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 7 with best_epoch = 6 and best_val_0_rmsle = 1.0486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 7 with best_epoch = 3 and best_val_0_rmsle = 1.68628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 7 with best_epoch = 6 and best_val_0_rmsle = 1.45929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 7 with best_epoch = 5 and best_val_0_rmsle = 1.34506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 7 with best_epoch = 6 and best_val_0_rmsle = 1.15865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:06:13,653]\u001b[0m Trial 2 finished with value: 1.339575297333715 and parameters: {'mask_type': 'sparsemax', 'n_da': 60, 'n_steps': 3, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 5.987474910461405e-05, 'cat_emb_dim': 1, 'patienceScheduler': 7, 'patience': 17, 'epochs': 7}. Best is trial 1 with value: 0.6839957645722059.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 91 with best_epoch = 88 and best_val_0_rmsle = 0.19135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 91 with best_epoch = 87 and best_val_0_rmsle = 0.19378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 91 with best_epoch = 83 and best_val_0_rmsle = 0.18513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 91 with best_epoch = 80 and best_val_0_rmsle = 0.18075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 91 with best_epoch = 90 and best_val_0_rmsle = 0.15721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:12:01,320]\u001b[0m Trial 3 finished with value: 0.18164447560223884 and parameters: {'mask_type': 'sparsemax', 'n_da': 64, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 3, 'lambda_sparse': 2.091498132903561e-05, 'cat_emb_dim': 2, 'patienceScheduler': 6, 'patience': 15, 'epochs': 91}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 60 with best_epoch = 57 and best_val_0_rmsle = 0.19237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 60 with best_epoch = 54 and best_val_0_rmsle = 0.22291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 60 with best_epoch = 53 and best_val_0_rmsle = 0.28356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 60 with best_epoch = 59 and best_val_0_rmsle = 0.21165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 60 with best_epoch = 59 and best_val_0_rmsle = 0.1813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:15:33,324]\u001b[0m Trial 4 finished with value: 0.21835815881903065 and parameters: {'mask_type': 'sparsemax', 'n_da': 56, 'n_steps': 2, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 0.0008105016126411582, 'cat_emb_dim': 8, 'patienceScheduler': 10, 'patience': 29, 'epochs': 60}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 55 with best_epoch = 53 and best_val_0_rmsle = 0.21669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 55 with best_epoch = 54 and best_val_0_rmsle = 0.24114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 55 with best_epoch = 53 and best_val_0_rmsle = 0.19171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 55 with best_epoch = 53 and best_val_0_rmsle = 0.19384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 55 with best_epoch = 53 and best_val_0_rmsle = 0.16154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:18:24,283]\u001b[0m Trial 5 finished with value: 0.20098093424115399 and parameters: {'mask_type': 'entmax', 'n_da': 56, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 6.516990611177181e-06, 'cat_emb_dim': 9, 'patienceScheduler': 5, 'patience': 19, 'epochs': 55}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 78 with best_epoch = 73 and best_val_0_rmsle = 0.30705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 78 with best_epoch = 76 and best_val_0_rmsle = 0.20696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 78 with best_epoch = 62 and best_val_0_rmsle = 0.21196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 78 with best_epoch = 75 and best_val_0_rmsle = 0.23109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 78 with best_epoch = 76 and best_val_0_rmsle = 0.19509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:24:37,900]\u001b[0m Trial 6 finished with value: 0.23043040107697627 and parameters: {'mask_type': 'sparsemax', 'n_da': 56, 'n_steps': 3, 'gamma': 1.4, 'n_shared': 1, 'lambda_sparse': 1.0388823104027941e-06, 'cat_emb_dim': 9, 'patienceScheduler': 8, 'patience': 26, 'epochs': 78}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 64 with best_epoch = 57 and best_val_0_rmsle = 0.24091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 64 with best_epoch = 63 and best_val_0_rmsle = 0.21755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 64 with best_epoch = 59 and best_val_0_rmsle = 0.20914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 64 with best_epoch = 55 and best_val_0_rmsle = 0.21133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 64 with best_epoch = 56 and best_val_0_rmsle = 0.19855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:29:15,134]\u001b[0m Trial 7 finished with value: 0.21549400403772845 and parameters: {'mask_type': 'sparsemax', 'n_da': 56, 'n_steps': 3, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 1.5512259126484753e-06, 'cat_emb_dim': 4, 'patienceScheduler': 5, 'patience': 26, 'epochs': 64}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 1 and best_val_0_rmsle = 2.2895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_rmsle = 1.90763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_rmsle = 1.66005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 1 and best_val_0_rmsle = 1.84679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 3 with best_epoch = 1 and best_val_0_rmsle = 1.89756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:29:33,733]\u001b[0m Trial 8 finished with value: 1.9203065916842292 and parameters: {'mask_type': 'entmax', 'n_da': 56, 'n_steps': 3, 'gamma': 1.4, 'n_shared': 2, 'lambda_sparse': 0.00020554245520150764, 'cat_emb_dim': 5, 'patienceScheduler': 7, 'patience': 21, 'epochs': 3}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 8 with best_epoch = 7 and best_val_0_rmsle = 2.75401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 8 with best_epoch = 7 and best_val_0_rmsle = 2.32897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 8 with best_epoch = 7 and best_val_0_rmsle = 2.32218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 8 with best_epoch = 7 and best_val_0_rmsle = 2.1955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 8 with best_epoch = 7 and best_val_0_rmsle = 2.3997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:30:06,701]\u001b[0m Trial 9 finished with value: 2.4000715017629486 and parameters: {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 1, 'gamma': 1.2, 'n_shared': 3, 'lambda_sparse': 5.595986878006084e-06, 'cat_emb_dim': 5, 'patienceScheduler': 9, 'patience': 18, 'epochs': 8}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_val_0_rmsle = 0.23825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_rmsle = 0.20343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_rmsle = 0.18887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_rmsle = 0.25876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_rmsle = 0.16863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:36:32,415]\u001b[0m Trial 10 finished with value: 0.21158468323687987 and parameters: {'mask_type': 'sparsemax', 'n_da': 64, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 3, 'lambda_sparse': 1.3831805735878796e-05, 'cat_emb_dim': 1, 'patienceScheduler': 3, 'patience': 15, 'epochs': 100}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 39 with best_epoch = 36 and best_val_0_rmsle = 0.25418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 39 with best_epoch = 35 and best_val_0_rmsle = 0.21365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 39 with best_epoch = 36 and best_val_0_rmsle = 0.21682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 39 with best_epoch = 34 and best_val_0_rmsle = 0.2424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 39 with best_epoch = 35 and best_val_0_rmsle = 0.22881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:39:09,282]\u001b[0m Trial 11 finished with value: 0.23117338688551864 and parameters: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 3, 'lambda_sparse': 9.012779589354664e-06, 'cat_emb_dim': 7, 'patienceScheduler': 5, 'patience': 20, 'epochs': 39}. Best is trial 3 with value: 0.18164447560223884.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_val_0_rmsle = 0.1621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_rmsle = 0.20866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 93 with best_epoch = 77 and best_val_0_rmsle = 0.15818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 85 and best_val_0_rmsle = 0.16507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_val_0_rmsle = 0.17389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:46:32,497]\u001b[0m Trial 12 finished with value: 0.17357980816829394 and parameters: {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 2, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 1.856186048678757e-05, 'cat_emb_dim': 3, 'patienceScheduler': 3, 'patience': 16, 'epochs': 100}. Best is trial 12 with value: 0.17357980816829394.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 57 with best_epoch = 42 and best_val_0_rmsle = 0.19784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 89 with best_epoch = 74 and best_val_0_rmsle = 0.17483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_val_0_rmsle = 0.21119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 100 with best_epoch = 86 and best_val_0_rmsle = 0.16414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 74 with best_epoch = 59 and best_val_0_rmsle = 0.17913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 18:54:01,635]\u001b[0m Trial 13 finished with value: 0.1854273036032204 and parameters: {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 2, 'gamma': 1.2, 'n_shared': 3, 'lambda_sparse': 2.4222252021885826e-05, 'cat_emb_dim': 3, 'patienceScheduler': 3, 'patience': 15, 'epochs': 100}. Best is trial 12 with value: 0.17357980816829394.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 76 and best_val_0_rmsle = 0.14448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 74 and best_val_0_rmsle = 0.15798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 78 and best_val_0_rmsle = 0.15548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 80 and best_val_0_rmsle = 0.14261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 78 and best_val_0_rmsle = 0.13632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 19:00:23,925]\u001b[0m Trial 14 finished with value: 0.14737630837159596 and parameters: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 2, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 7.462098991355312e-05, 'cat_emb_dim': 3, 'patienceScheduler': 4, 'patience': 17, 'epochs': 82}. Best is trial 14 with value: 0.14737630837159596.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 76 with best_epoch = 67 and best_val_0_rmsle = 0.18239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 76 with best_epoch = 72 and best_val_0_rmsle = 0.1712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 76 with best_epoch = 69 and best_val_0_rmsle = 0.18578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 76 with best_epoch = 68 and best_val_0_rmsle = 0.16972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 76 with best_epoch = 73 and best_val_0_rmsle = 0.16928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 19:06:01,130]\u001b[0m Trial 15 finished with value: 0.1756725589208327 and parameters: {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 2, 'gamma': 1.2, 'n_shared': 2, 'lambda_sparse': 8.28715379790703e-05, 'cat_emb_dim': 3, 'patienceScheduler': 3, 'patience': 22, 'epochs': 76}. Best is trial 14 with value: 0.14737630837159596.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 78 and best_val_0_rmsle = 0.1716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 77 and best_val_0_rmsle = 0.19604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 77 and best_val_0_rmsle = 0.15259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 81 and best_val_0_rmsle = 0.17162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 70 and best_val_0_rmsle = 0.15039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 19:12:16,561]\u001b[0m Trial 16 finished with value: 0.16844998630294755 and parameters: {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 2, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 0.00012460145760560812, 'cat_emb_dim': 3, 'patienceScheduler': 4, 'patience': 17, 'epochs': 82}. Best is trial 14 with value: 0.14737630837159596.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 80 with best_epoch = 62 and best_val_0_rmsle = 0.17311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 74 and best_val_0_rmsle = 0.15858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 78 and best_val_0_rmsle = 0.15854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 80 and best_val_0_rmsle = 0.14197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 82 with best_epoch = 81 and best_val_0_rmsle = 0.14536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 19:19:12,767]\u001b[0m Trial 17 finished with value: 0.15551369712108137 and parameters: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 2, 'gamma': 1.4, 'n_shared': 2, 'lambda_sparse': 0.00016893806027344123, 'cat_emb_dim': 7, 'patienceScheduler': 4, 'patience': 18, 'epochs': 82}. Best is trial 14 with value: 0.14737630837159596.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 43 with best_epoch = 40 and best_val_0_rmsle = 0.25024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 43 with best_epoch = 42 and best_val_0_rmsle = 0.20814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 43 with best_epoch = 41 and best_val_0_rmsle = 0.21139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 43 with best_epoch = 40 and best_val_0_rmsle = 0.18893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 43 with best_epoch = 42 and best_val_0_rmsle = 0.18013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 19:22:46,474]\u001b[0m Trial 18 finished with value: 0.20776524051616246 and parameters: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 2, 'gamma': 1.4, 'n_shared': 2, 'lambda_sparse': 0.0002697652275447117, 'cat_emb_dim': 7, 'patienceScheduler': 4, 'patience': 19, 'epochs': 43}. Best is trial 14 with value: 0.14737630837159596.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 70 with best_epoch = 63 and best_val_0_rmsle = 0.17015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_val_0_rmsle = 0.14928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_val_0_rmsle = 0.16953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_val_0_rmsle = 0.15696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_val_0_rmsle = 0.16215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "\u001b[32m[I 2023-03-23 19:28:32,754]\u001b[0m Trial 19 finished with value: 0.16161526546615618 and parameters: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 2, 'gamma': 1.4, 'n_shared': 2, 'lambda_sparse': 0.0004099227036801607, 'cat_emb_dim': 7, 'patienceScheduler': 4, 'patience': 22, 'epochs': 70}. Best is trial 14 with value: 0.14737630837159596.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.14737630837159596\n",
            "Best trial: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 2, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 7.462098991355312e-05, 'cat_emb_dim': 3, 'patienceScheduler': 4, 'patience': 17, 'epochs': 82}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "GU_ABIE24PQy",
        "outputId": "2f3374a9-d5fb-4782-a7c0-de8be893000d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"68b727fc-74e1-4366-89c7-61b21b8fb1e5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"68b727fc-74e1-4366-89c7-61b21b8fb1e5\")) {                    Plotly.newPlot(                        \"68b727fc-74e1-4366-89c7-61b21b8fb1e5\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[3.110781105755272,0.6839957645722059,1.339575297333715,0.18164447560223884,0.21835815881903065,0.20098093424115399,0.23043040107697627,0.21549400403772845,1.9203065916842292,2.4000715017629486,0.21158468323687987,0.23117338688551864,0.17357980816829394,0.1854273036032204,0.14737630837159596,0.1756725589208327,0.16844998630294755,0.15551369712108137,0.20776524051616246,0.16161526546615618],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[3.110781105755272,0.6839957645722059,0.6839957645722059,0.18164447560223884,0.18164447560223884,0.18164447560223884,0.18164447560223884,0.18164447560223884,0.18164447560223884,0.18164447560223884,0.18164447560223884,0.18164447560223884,0.17357980816829394,0.17357980816829394,0.14737630837159596,0.14737630837159596,0.14737630837159596,0.14737630837159596,0.14737630837159596,0.14737630837159596],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('68b727fc-74e1-4366-89c7-61b21b8fb1e5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 중요도\n",
        "optuna.visualization.plot_param_importances(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "LQPvQ7BE4d4e",
        "outputId": "3f9271a0-f9b6-48d6-e25e-dca2493920d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"d9319053-f1c8-41e4-9642-8d26bf2d2f6f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d9319053-f1c8-41e4-9642-8d26bf2d2f6f\")) {                    Plotly.newPlot(                        \"d9319053-f1c8-41e4-9642-8d26bf2d2f6f\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"lambda_sparse (FloatDistribution): 0.00022766331743735352<extra></extra>\",\"n_shared (IntDistribution): 0.0003743260096409067<extra></extra>\",\"gamma (FloatDistribution): 0.00047330312586243273<extra></extra>\",\"n_da (IntDistribution): 0.000698319745958033<extra></extra>\",\"cat_emb_dim (IntDistribution): 0.0020566308082159324<extra></extra>\",\"mask_type (CategoricalDistribution): 0.002276977144662521<extra></extra>\",\"patience (IntDistribution): 0.009025793168810766<extra></extra>\",\"n_steps (IntDistribution): 0.02830943166385333<extra></extra>\",\"patienceScheduler (IntDistribution): 0.031007843946730777<extra></extra>\",\"epochs (IntDistribution): 0.9255497110688279<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"<0.01\",\"<0.01\",\"<0.01\",\"<0.01\",\"<0.01\",\"<0.01\",\"<0.01\",\"0.03\",\"0.03\",\"0.93\"],\"textposition\":\"outside\",\"x\":[0.00022766331743735352,0.0003743260096409067,0.00047330312586243273,0.000698319745958033,0.0020566308082159324,0.002276977144662521,0.009025793168810766,0.02830943166385333,0.031007843946730777,0.9255497110688279],\"y\":[\"lambda_sparse\",\"n_shared\",\"gamma\",\"n_da\",\"cat_emb_dim\",\"mask_type\",\"patience\",\"n_steps\",\"patienceScheduler\",\"epochs\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d9319053-f1c8-41e4-9642-8d26bf2d2f6f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_trial.params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ARKU4704f_x",
        "outputId": "309ebe41-6ca7-436e-c081-b2526fed81db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mask_type': 'entmax',\n",
              " 'n_da': 64,\n",
              " 'n_steps': 2,\n",
              " 'gamma': 1.0,\n",
              " 'n_shared': 2,\n",
              " 'lambda_sparse': 7.462098991355312e-05,\n",
              " 'cat_emb_dim': 3,\n",
              " 'patienceScheduler': 4,\n",
              " 'patience': 17,\n",
              " 'epochs': 82}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {\"mask_type\": \"entmax\",\n",
        "                \"n_da\": 64,\n",
        "                \"n_steps\": 2,\n",
        "                \"gamma\": 1.0,\n",
        "                \"n_shared\": 2,\n",
        "                \"lambda_sparse\": 7.462098991355312e-05,\n",
        "                \"cat_emb_dim\": 3,\n",
        "                \"patienceScheduler\": 4,\n",
        "                \"patience\": 17, \"epochs\": 82, \"cat_idxs\": cat_idxs,\n",
        "                \"cat_dims\": cat_dims}"
      ],
      "metadata": {
        "id": "taGZlgIgzC4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet_params = dict(n_d=64, n_a=64, n_steps=3, gamma=1.0,\n",
        "                     lambda_sparse=7.462098991355312e-05, optimizer_fn=torch.optim.Adam,\n",
        "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
        "                     mask_type=\"entmax\", n_shared= 2,\n",
        "                     scheduler_params=dict(mode=\"min\",\n",
        "                                           patience=4,\n",
        "                                           min_lr=1e-5,\n",
        "                                           factor=0.5,),\n",
        "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "                     verbose=0,\n",
        "                     cat_idxs = cat_idxs,\n",
        "                     cat_dims = cat_dims,\n",
        "                     cat_emb_dim=3\n",
        "                     )"
      ],
      "metadata": {
        "id": "ID0E7xGZ1Wzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = TabNetRegressor(**tabnet_params)\n",
        "regressor.fit(xtrain_t.values, np.array(y_train).reshape(-1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKfVch7OzIk7",
        "outputId": "39c32b7c-55d6-4c3e-b368-c504d181af4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(xtest_t.values)\n",
        "y_pred = np.where(y_pred<0, 0, y_pred)\n",
        "test_rmsle = mean_squared_log_error(y_test, y_pred, squared=True)\n",
        "print(test_rmsle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKcVby_QzvyN",
        "outputId": "a2617f64-1017-4f87-d56f-a5d2b7b5b15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2448928761857799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.where(y_pred<0, 0, y_pred)"
      ],
      "metadata": {
        "id": "6pgxHM0g3g1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[y_pred<0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vePk1G9U29tZ",
        "outputId": "8cd5c0b6-1de4-4242-d1e7-9d67278a1a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.2504969 , -0.76534986], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 제출"
      ],
      "metadata": {
        "id": "rEKsMx8n2umP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = \"/content/drive/MyDrive/함께하조/기계학습과 딥러닝/data/kaggle_data/test_eda.csv\"\n",
        "train_path = \"/content/drive/MyDrive/함께하조/기계학습과 딥러닝/data/kaggle_data/train_eda.csv\"\n",
        "\n",
        "test = pd.read_csv(test_path)\n",
        "train = pd.read_csv(train_path)\n",
        "\n",
        "test.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "train.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "\n",
        "#cat features\n",
        "cat_col = [\"season\", \"Year\",\"weather\", \"Day of week\",\"Month\",\"Day_info\"] #Hour\n",
        "for col in cat_col:\n",
        "    train[col] = train[col].astype(\"category\")\n",
        "    test[col] = test[col].astype(\"category\")\n",
        "\n",
        "\n",
        "\n",
        "#target, drop, y\n",
        "target_col = \"count\"\n",
        "drop_cols = [\"datetime\", \"workingday\", \"holiday\", \"Day\", \"Year\", \"Hour\",target_col] #\"sin_hour\", \"cos_hour\"\n",
        "\n",
        "x_train, y_train = train.drop(drop_cols, axis=1), train[target_col]\n",
        "x_test = test.drop([\"datetime\", \"workingday\", \"holiday\", \"Day\", \"Year\", \"Hour\"], axis=1)\n",
        "\n",
        "x_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X0DZ821j2rJp",
        "outputId": "785fb15a-3f13-4d0d-ed6e-f22e0dfcfbeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  season weather  temp  humidity  windspeed Day of week Month Day_info  \\\n",
              "0      1    Good  9.84        81        0.0    Saturday     1  Weekend   \n",
              "1      1    Good  9.02        80        0.0    Saturday     1  Weekend   \n",
              "2      1    Good  9.02        80        0.0    Saturday     1  Weekend   \n",
              "3      1    Good  9.84        75        0.0    Saturday     1  Weekend   \n",
              "4      1    Good  9.84        75        0.0    Saturday     1  Weekend   \n",
              "\n",
              "   sin_hour  cos_hour  \n",
              "0  0.000000  1.000000  \n",
              "1  0.258819  0.965926  \n",
              "2  0.500000  0.866025  \n",
              "3  0.707107  0.707107  \n",
              "4  0.866025  0.500000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cdaaf63-47ac-4171-bdcc-b79a895348fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>Day of week</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day_info</th>\n",
              "      <th>sin_hour</th>\n",
              "      <th>cos_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>0.965926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>Weekend</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cdaaf63-47ac-4171-bdcc-b79a895348fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cdaaf63-47ac-4171-bdcc-b79a895348fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cdaaf63-47ac-4171-bdcc-b79a895348fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcle =  MultiColLabelEncoder()\n",
        "cat_cols = [\"season\", \"weather\", \"Day of week\", \"Month\", \"Day_info\"] \n",
        "xtrain_t = mcle.fit_transform(x_train, columns=cat_cols)\n",
        "xtest_t = mcle.fit_transform(x_test, columns=cat_cols)\n",
        "xtrain_t.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uFxSipxl3-gA",
        "outputId": "7736252f-498b-4891-8fc1-63edfd7be58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   season  weather  temp  humidity  windspeed  Day of week  Month  Day_info  \\\n",
              "0       0        0  9.84        81        0.0            2      0         0   \n",
              "1       0        0  9.02        80        0.0            2      0         0   \n",
              "2       0        0  9.02        80        0.0            2      0         0   \n",
              "3       0        0  9.84        75        0.0            2      0         0   \n",
              "4       0        0  9.84        75        0.0            2      0         0   \n",
              "\n",
              "   sin_hour  cos_hour  \n",
              "0  0.000000  1.000000  \n",
              "1  0.258819  0.965926  \n",
              "2  0.500000  0.866025  \n",
              "3  0.707107  0.707107  \n",
              "4  0.866025  0.500000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a21b193-763e-4ff7-9dd9-0dc04f6d4f05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>Day of week</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day_info</th>\n",
              "      <th>sin_hour</th>\n",
              "      <th>cos_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.84</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.258819</td>\n",
              "      <td>0.965926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.02</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.84</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a21b193-763e-4ff7-9dd9-0dc04f6d4f05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a21b193-763e-4ff7-9dd9-0dc04f6d4f05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a21b193-763e-4ff7-9dd9-0dc04f6d4f05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = TabNetRegressor(**tabnet_params)\n",
        "regressor.fit(xtrain_t.values, np.array(y_train).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "sG07ecFnAuHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22781cc3-0f15-4c4b-e67a-4738734956f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(xtest_t.values)\n",
        "y_pred = np.where(y_pred<0, 0, y_pred)\n",
        "\n",
        "test[\"count\"] = y_pred\n",
        "submission = test[[\"datetime\", \"count\"]]\n",
        "submission.head()\n",
        "\n",
        "# 0.442\n",
        "submission.to_csv(\"TABNetr.csv\", index=False)"
      ],
      "metadata": {
        "id": "pUv1vBGq4JtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUwjruMX41-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}